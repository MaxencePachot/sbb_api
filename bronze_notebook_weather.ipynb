{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8296bff3-9630-4ef8-a258-81b4efaf5419",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1️⃣ Variables\n",
    "# -------------------------------\n",
    "storage_account = \"sbbapistorageaccount\"\n",
    "container = \"data-container\"\n",
    "account_key = \"\"\n",
    "\n",
    "# Spark configuration (only needed if not already set in your cluster)\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\",\n",
    "    account_key\n",
    ")\n",
    "\n",
    "# ADLS paths\n",
    "weather_csv_path = f\"abfss://{container}@{storage_account}.dfs.core.windows.net/data/weather-data.csv\"\n",
    "weather_params_csv_path = f\"abfss://{container}@{storage_account}.dfs.core.windows.net/data/weather-data-parameters.csv\"\n",
    "\n",
    "bronze_weather_path = f\"abfss://{container}@{storage_account}.dfs.core.windows.net/bronze/weather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fee7f382-2aef-44eb-8ee3-163cae0844db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2️⃣ Read raw CSV files\n",
    "# -------------------------------\n",
    "df_weather = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(weather_csv_path)\n",
    ")\n",
    "\n",
    "df_params = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(weather_params_csv_path)\n",
    ")\n",
    "\n",
    "print(\"✅ CSV files successfully loaded\")\n",
    "df_weather.show(5, truncate=False)\n",
    "df_params.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de514039-3ca1-41da-b02c-b016bca13775",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3️⃣ Check schema\n",
    "# -------------------------------\n",
    "df_weather.printSchema()\n",
    "df_params.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "406e9440-2893-4e9c-9a2f-4eebdf5a20b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4️⃣ Clean data (littlebit) & Write Bronze Delta tables\n",
    "# -------------------------------\n",
    "def clean_column(colname):\n",
    "    return (\n",
    "        colname.strip()              # remove leading/trailing spaces\n",
    "              .lower()               # lowercase\n",
    "              .replace(\" \", \"_\")     # replace spaces with underscores\n",
    "              .replace(\";\", \"_\")     # replace semicolons\n",
    "              .replace(\"(\", \"\")      # remove (\n",
    "              .replace(\")\", \"\")      # remove )\n",
    "              .replace(\"{\", \"\")      # remove {\n",
    "              .replace(\"}\", \"\")      # remove }\n",
    "              .replace(\"=\", \"_\")     # replace =\n",
    "              .replace(\"-\", \"_\")     # replace hyphen with underscore\n",
    "    )\n",
    "\n",
    "df_weather = df_weather.toDF(*[clean_column(c) for c in df_weather.columns])\n",
    "df_params = df_params.toDF(*[clean_column(c) for c in df_params.columns])\n",
    "\n",
    "# 3️⃣ Write to Bronze Delta\n",
    "df_weather.write.format(\"delta\").mode(\"overwrite\").save(bronze_weather_path + \"/data\")\n",
    "df_params.write.format(\"delta\").mode(\"overwrite\").save(bronze_weather_path + \"/params\")\n",
    "\n",
    "print(\"✅ Weather (data & params) Bronze tables saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1946f3cc-117f-4a52-895c-23d3ceff6814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 5️⃣ Register SQL tables\n",
    "# -------------------------------\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bronze_weather_data\n",
    "USING DELTA\n",
    "LOCATION '{bronze_weather_path}/data'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS bronze_weather_parameters\n",
    "USING DELTA\n",
    "LOCATION '{bronze_weather_path}/params'\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ SQL tables bronze_weather_data and bronze_weather_parameters successfully created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61a4fdc3-fa44-489c-9f6b-91e41f6208fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "SELECT *\n",
    "FROM bronze_weather_data\n",
    "LIMIT 3\n",
    "\"\"\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_notebook_weather",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
